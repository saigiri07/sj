{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4m-MH7zySllY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input\n",
        "import random\n",
        "import sys\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset (Example: Shakespeare Sonnets)\n",
        "path = tf.keras.utils.get_file(\"shakespeare.txt\", \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\")\n",
        "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read().lower()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at27UzRxSwyK",
        "outputId": "5cf6eb5d-ac73-44ff-86d1-45fb17590c85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare character mapping\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_idx = {c: i for i, c in enumerate(chars)}\n",
        "idx_to_char = {i: c for i, c in enumerate(chars)}\n",
        "\n",
        "# Create sequences\n",
        "seq_length = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - seq_length, step):\n",
        "    sentences.append(text[i: i + seq_length])\n",
        "    next_chars.append(text[i + seq_length])\n",
        "\n",
        "X = np.zeros((len(sentences), seq_length, len(chars)), dtype=np.bool_)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool_)\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t, char_to_idx[char]] = 1\n",
        "    y[i, char_to_idx[next_chars[i]]] = 1\n"
      ],
      "metadata": {
        "id": "KYodPkHhS5cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define RNN model\n",
        "model = Sequential([\n",
        "    Input(shape=(seq_length, len(chars))),\n",
        "    LSTM(128),\n",
        "    Dense(len(chars), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Train model\n",
        "model.fit(X, y, batch_size=128, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HewUAiUpS8so",
        "outputId": "8f0e72ce-5e2a-44d8-f78a-87fd7f1a170d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - loss: 2.5751\n",
            "Epoch 2/10\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - loss: 1.9803\n",
            "Epoch 3/10\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 1.7911\n",
            "Epoch 4/10\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 1.6867\n",
            "Epoch 5/10\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 1.6249\n",
            "Epoch 6/10\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 1.5754\n",
            "Epoch 7/10\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 1.5335\n",
            "Epoch 8/10\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - loss: 1.5049\n",
            "Epoch 9/10\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 1.4788\n",
            "Epoch 10/10\n",
            "\u001b[1m2905/2905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 1.4592\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7996782061d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for text generation\n",
        "def generate_text(seed_text, length=200, temperature=1.0):\n",
        "    generated = seed_text\n",
        "    for _ in range(length):\n",
        "        x_pred = np.zeros((1, seq_length, len(chars)))\n",
        "        for t, char in enumerate(seed_text):\n",
        "            x_pred[0, t, char_to_idx[char]] = 1\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        preds = np.asarray(preds).astype(\"float64\")\n",
        "        preds = np.log(preds) / temperature\n",
        "        exp_preds = np.exp(preds)\n",
        "        preds = exp_preds / np.sum(exp_preds)\n",
        "        next_index = np.random.choice(len(chars), p=preds)\n",
        "        next_char = idx_to_char[next_index]\n",
        "        generated += next_char\n",
        "        seed_text = seed_text[1:] + next_char\n",
        "    return generated"
      ],
      "metadata": {
        "id": "3s7H6NPiTDbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example text generation\n",
        "seed = \"shall i compare thee to a summer's day? \"\n",
        "print(generate_text(seed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPZycrkGVG6k",
        "outputId": "55aefbd5-c92e-4408-ba03-af8dba1ef5db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shall i compare thee to a summer's day? go.\n",
            "go, should stil his tome, what, i'll came\n",
            "their wornistith: his iest a feire him: and\n",
            "to him from so suck, a dufe like in my sunder,\n",
            "our baurmand asteds to stene andervice,\n",
            "but his out my such our\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gyCJpSyRXbli"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}